{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from math import sqrt\n",
    "import math\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from tqdm import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel():\n",
    "    def __init__(self, X_tr, y_tr, X_val, y_val, X_test):\n",
    "        self.X_tr = X_tr\n",
    "        self.y_tr = y_tr\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.X_test = X_test\n",
    "        self.params = {}\n",
    "    def predict_val(self):\n",
    "        return self.model.predict(self.X_val)\n",
    "    def predict_test(self):\n",
    "        return self.model.predict(self.X_test)\n",
    "\n",
    "\n",
    "class LgbBoostModel(MyModel):\n",
    "    def train(self):          \n",
    "        self.params = { 'objective': 'regression', 'metric': 'rmse', 'boosting': 'gbdt', 'seed':seed, 'is_training_metric': True\n",
    "                  ,'max_bin': 350 #,'max_bin': 150\n",
    "                  ,'learning_rate': .005\n",
    "                  ,'max_depth': -1                  \n",
    "                  ,'num_leaves': 48\n",
    "                  ,'feature_fraction': 0.1\n",
    "                  ,'reg_alpha': 0\n",
    "                  ,'reg_lambda': 0.2\n",
    "                  ,'min_child_weight': 10}\n",
    "        \n",
    "        self.model = lgb.train(self.params, lgb.Dataset(self.X_tr, label=self.y_tr), 30000, \n",
    "                            [lgb.Dataset(self.X_tr, label=self.y_tr), lgb.Dataset(self.X_val, label=self.y_val)], \n",
    "                               verbose_eval=200, early_stopping_rounds=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "#train_feats = pd.read_csv('../input/train_agg_feats.csv')\n",
    "#test_feats = pd.read_csv('../input/test_agg_feats.csv')\n",
    "#test_patterns = pd.read_csv('../input/test_patterns_only_7830.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12289, 1287)\n",
      "(49342, 1287)\n"
     ]
    }
   ],
   "source": [
    "#Make training data from the original training plus the pattern in test data. This is key to improve our model prediction ability\n",
    "cols = train_feats.columns[1:]\n",
    "train_feat_final = pd.concat([train_feats[cols], test_feats[cols][test_patterns.target != 0]], axis = 0)\n",
    "train_feat_id = pd.concat([train['ID'], test['ID'][test_patterns.target != 0]], axis = 0)\n",
    "test_feat_final = test_feats[cols]    \n",
    "y = np.array(list(np.log1p(train.target.values)) + list(np.log1p(test_patterns['target'][test_patterns.target != 0])))\n",
    "\n",
    "X = train_feat_final.values\n",
    "X_test = test_feat_final.values\n",
    "\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 fold..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4129f68d42844233b02b9e91e70ffe13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.34384\tvalid_1's rmse: 1.42626\n",
      "[400]\tvalid_0's rmse: 1.19803\tvalid_1's rmse: 1.35876\n",
      "[600]\tvalid_0's rmse: 1.12229\tvalid_1's rmse: 1.34843\n",
      "[800]\tvalid_0's rmse: 1.06631\tvalid_1's rmse: 1.34684\n",
      "[1000]\tvalid_0's rmse: 1.01976\tvalid_1's rmse: 1.34707\n",
      "Early stopping, best iteration is:\n",
      "[830]\tvalid_0's rmse: 1.05886\tvalid_1's rmse: 1.34664\n",
      "Fold 0: lgb Mean Squared Error 1.346639\n",
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.34118\tvalid_1's rmse: 1.47594\n",
      "[400]\tvalid_0's rmse: 1.19771\tvalid_1's rmse: 1.39015\n",
      "[600]\tvalid_0's rmse: 1.12306\tvalid_1's rmse: 1.3704\n",
      "[800]\tvalid_0's rmse: 1.06753\tvalid_1's rmse: 1.36359\n",
      "[1000]\tvalid_0's rmse: 1.02145\tvalid_1's rmse: 1.35995\n",
      "[1200]\tvalid_0's rmse: 0.981049\tvalid_1's rmse: 1.35787\n",
      "[1400]\tvalid_0's rmse: 0.943892\tvalid_1's rmse: 1.35732\n",
      "[1600]\tvalid_0's rmse: 0.90924\tvalid_1's rmse: 1.35657\n",
      "[1800]\tvalid_0's rmse: 0.876923\tvalid_1's rmse: 1.35608\n",
      "[2000]\tvalid_0's rmse: 0.846856\tvalid_1's rmse: 1.35581\n",
      "[2200]\tvalid_0's rmse: 0.818035\tvalid_1's rmse: 1.35572\n",
      "[2400]\tvalid_0's rmse: 0.791148\tvalid_1's rmse: 1.35469\n",
      "[2600]\tvalid_0's rmse: 0.766403\tvalid_1's rmse: 1.35427\n",
      "[2800]\tvalid_0's rmse: 0.742317\tvalid_1's rmse: 1.35422\n",
      "[3000]\tvalid_0's rmse: 0.71955\tvalid_1's rmse: 1.35375\n",
      "[3200]\tvalid_0's rmse: 0.698442\tvalid_1's rmse: 1.35414\n",
      "Early stopping, best iteration is:\n",
      "[3006]\tvalid_0's rmse: 0.718951\tvalid_1's rmse: 1.35373\n",
      "Fold 1: lgb Mean Squared Error 1.353730\n",
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.34996\tvalid_1's rmse: 1.38389\n",
      "[400]\tvalid_0's rmse: 1.20562\tvalid_1's rmse: 1.30305\n",
      "[600]\tvalid_0's rmse: 1.13031\tvalid_1's rmse: 1.28558\n",
      "[800]\tvalid_0's rmse: 1.07448\tvalid_1's rmse: 1.28044\n",
      "[1000]\tvalid_0's rmse: 1.02807\tvalid_1's rmse: 1.27796\n",
      "[1200]\tvalid_0's rmse: 0.988011\tvalid_1's rmse: 1.2765\n",
      "[1400]\tvalid_0's rmse: 0.951147\tvalid_1's rmse: 1.27698\n",
      "[1600]\tvalid_0's rmse: 0.916767\tvalid_1's rmse: 1.27636\n",
      "[1800]\tvalid_0's rmse: 0.884777\tvalid_1's rmse: 1.27699\n",
      "Early stopping, best iteration is:\n",
      "[1612]\tvalid_0's rmse: 0.914746\tvalid_1's rmse: 1.2762\n",
      "Fold 2: lgb Mean Squared Error 1.276197\n",
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.35\tvalid_1's rmse: 1.38221\n",
      "[400]\tvalid_0's rmse: 1.20524\tvalid_1's rmse: 1.30186\n",
      "[600]\tvalid_0's rmse: 1.12966\tvalid_1's rmse: 1.28646\n",
      "[800]\tvalid_0's rmse: 1.07378\tvalid_1's rmse: 1.28283\n",
      "[1000]\tvalid_0's rmse: 1.02669\tvalid_1's rmse: 1.28203\n",
      "[1200]\tvalid_0's rmse: 0.985932\tvalid_1's rmse: 1.28164\n",
      "[1400]\tvalid_0's rmse: 0.948847\tvalid_1's rmse: 1.28233\n",
      "Early stopping, best iteration is:\n",
      "[1251]\tvalid_0's rmse: 0.976304\tvalid_1's rmse: 1.2815\n",
      "Fold 3: lgb Mean Squared Error 1.281501\n",
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.3466\tvalid_1's rmse: 1.39654\n",
      "[400]\tvalid_0's rmse: 1.20023\tvalid_1's rmse: 1.33781\n",
      "[600]\tvalid_0's rmse: 1.12472\tvalid_1's rmse: 1.32969\n",
      "[800]\tvalid_0's rmse: 1.06824\tvalid_1's rmse: 1.32891\n",
      "Early stopping, best iteration is:\n",
      "[743]\tvalid_0's rmse: 1.0833\tvalid_1's rmse: 1.32835\n",
      "Fold 4: lgb Mean Squared Error 1.328348\n",
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.34988\tvalid_1's rmse: 1.39236\n",
      "[400]\tvalid_0's rmse: 1.20582\tvalid_1's rmse: 1.3061\n",
      "[600]\tvalid_0's rmse: 1.13041\tvalid_1's rmse: 1.28594\n",
      "[800]\tvalid_0's rmse: 1.0739\tvalid_1's rmse: 1.27989\n",
      "[1000]\tvalid_0's rmse: 1.02717\tvalid_1's rmse: 1.27717\n",
      "[1200]\tvalid_0's rmse: 0.986285\tvalid_1's rmse: 1.27647\n",
      "[1400]\tvalid_0's rmse: 0.949268\tvalid_1's rmse: 1.27592\n",
      "Early stopping, best iteration is:\n",
      "[1316]\tvalid_0's rmse: 0.964375\tvalid_1's rmse: 1.27548\n",
      "Fold 5: lgb Mean Squared Error 1.275484\n",
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.34778\tvalid_1's rmse: 1.40577\n",
      "[400]\tvalid_0's rmse: 1.20353\tvalid_1's rmse: 1.32953\n",
      "[600]\tvalid_0's rmse: 1.12816\tvalid_1's rmse: 1.31558\n",
      "[800]\tvalid_0's rmse: 1.0724\tvalid_1's rmse: 1.3128\n",
      "[1000]\tvalid_0's rmse: 1.02641\tvalid_1's rmse: 1.31149\n",
      "Early stopping, best iteration is:\n",
      "[966]\tvalid_0's rmse: 1.03376\tvalid_1's rmse: 1.31136\n",
      "Fold 6: lgb Mean Squared Error 1.311359\n",
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.34449\tvalid_1's rmse: 1.43641\n",
      "[400]\tvalid_0's rmse: 1.19992\tvalid_1's rmse: 1.36118\n",
      "[600]\tvalid_0's rmse: 1.12495\tvalid_1's rmse: 1.34541\n",
      "[800]\tvalid_0's rmse: 1.06885\tvalid_1's rmse: 1.34246\n",
      "[1000]\tvalid_0's rmse: 1.02304\tvalid_1's rmse: 1.34313\n",
      "Early stopping, best iteration is:\n",
      "[863]\tvalid_0's rmse: 1.05344\tvalid_1's rmse: 1.34215\n",
      "Fold 7: lgb Mean Squared Error 1.342153\n",
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.34711\tvalid_1's rmse: 1.41228\n",
      "[400]\tvalid_0's rmse: 1.20293\tvalid_1's rmse: 1.33208\n",
      "[600]\tvalid_0's rmse: 1.12781\tvalid_1's rmse: 1.31447\n",
      "[800]\tvalid_0's rmse: 1.07209\tvalid_1's rmse: 1.31002\n",
      "[1000]\tvalid_0's rmse: 1.02614\tvalid_1's rmse: 1.30932\n",
      "[1200]\tvalid_0's rmse: 0.986869\tvalid_1's rmse: 1.30903\n",
      "Early stopping, best iteration is:\n",
      "[1123]\tvalid_0's rmse: 1.00158\tvalid_1's rmse: 1.30868\n",
      "Fold 8: lgb Mean Squared Error 1.308683\n",
      "\n",
      "*** lgb\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's rmse: 1.34626\tvalid_1's rmse: 1.42402\n",
      "[400]\tvalid_0's rmse: 1.20259\tvalid_1's rmse: 1.3375\n",
      "[600]\tvalid_0's rmse: 1.12752\tvalid_1's rmse: 1.31695\n",
      "[800]\tvalid_0's rmse: 1.07195\tvalid_1's rmse: 1.31074\n",
      "[1000]\tvalid_0's rmse: 1.02561\tvalid_1's rmse: 1.30837\n",
      "[1200]\tvalid_0's rmse: 0.985111\tvalid_1's rmse: 1.30747\n",
      "[1400]\tvalid_0's rmse: 0.948409\tvalid_1's rmse: 1.3071\n",
      "[1600]\tvalid_0's rmse: 0.914675\tvalid_1's rmse: 1.30629\n",
      "[1800]\tvalid_0's rmse: 0.882387\tvalid_1's rmse: 1.30628\n",
      "Early stopping, best iteration is:\n",
      "[1698]\tvalid_0's rmse: 0.898635\tvalid_1's rmse: 1.30611\n",
      "Fold 9: lgb Mean Squared Error 1.306110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "seed = 42\n",
    "\n",
    "kf = KFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "\n",
    "\n",
    "rmse_scores = {}\n",
    "oof_preds = {}\n",
    "sub_preds = {}\n",
    "model_params = {}\n",
    "\n",
    "model_types = ['lgb']\n",
    "\n",
    "for model_type in model_types:\n",
    "    rmse_scores[model_type] = list()\n",
    "    oof_preds[model_type] = np.zeros((X.shape[0],))\n",
    "    sub_preds[model_type] = np.zeros((X_test.shape[0],))\n",
    "\n",
    "print('{} fold..'.format(n_splits))\n",
    "\n",
    "for fold, (train_index, test_index) in tqdm_notebook(list(enumerate(list(kf.split(y))[:]))):\n",
    "\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_tr, X_val = X[train_index], X[test_index]\n",
    "    y_tr, y_val = y[train_index], y[test_index]\n",
    "\n",
    "    for model_type in model_types:\n",
    "        print ('\\n*** ' + model_type)\n",
    "        #model = get_model_class(model_type,  X_tr, y_tr, X_val, y_val, X_test)\n",
    "        model = LgbBoostModel(X_tr, y_tr, X_val, y_val, X_test)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        oof_preds[model_type][test_index] = model.predict_val()\n",
    "        sub_preds[model_type] += model.predict_test() / n_splits        \n",
    "        rmse = mean_squared_error(y_val, model.predict_val())**0.5\n",
    "        rmse_scores[model_type].append(rmse)\n",
    "\n",
    "        model.params['cv'] = n_splits\n",
    "        #model.params['fold_by_target'] = fold_by_target\n",
    "        model.params['seed'] = seed            \n",
    "        model_params[model_type] = model.params\n",
    "\n",
    "        print('Fold %d: %s Mean Squared Error %f'%(fold, model_type, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb Mean Squared Error 1.3130204655072009\n",
      "lgb Stdev Squared Error 0.027746778383404516\n"
     ]
    }
   ],
   "source": [
    "def mean(values):\n",
    "    return float(sum(values)) / max(len(values), 1)\n",
    "\n",
    "def sum_of_square_deviation(values, mean):\n",
    "    return float(1/len(values) * sum((x - mean)** 2 for x in values))  \n",
    "\n",
    "subm = pd.read_csv('../input/sample_submission.csv')\n",
    "subm['target'] = np.expm1(sub_preds[model_type])\n",
    "\n",
    "oof = pd.DataFrame(train_feat_id.copy())\n",
    "oof['target'] = np.expm1(y)\n",
    "oof['prediction'] = np.expm1(oof_preds[model_type])\n",
    "mean_rmse = np.mean(rmse_scores[model_type])\n",
    "standard_deviation_rmse = np.std(rmse_scores[model_type])\n",
    "key = '{}'.format(model_type)\n",
    "print( '{} Mean Squared Error {}'.format(model_type ,mean_rmse))\n",
    "print( '{} Stdev Squared Error {}'.format(model_type, standard_deviation_rmse))\n",
    "file_name = '../output/submission.csv'.format(key)    \n",
    "subm['target'][test_patterns.target != 0] = test_patterns['target'][test_patterns.target != 0]\n",
    "subm.to_csv(file_name, index=False, float_format=\"%.8f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
